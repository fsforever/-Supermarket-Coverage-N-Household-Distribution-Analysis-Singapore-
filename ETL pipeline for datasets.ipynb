{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4abb47d0-615c-454e-881f-835447183319",
   "metadata": {},
   "source": [
    "!pip install geopandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bbf2ee-56a0-49ec-b147-c2571664fc7c",
   "metadata": {},
   "source": [
    "### import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f426584-b091-4e17-81a8-2f1a2aef04cb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# =========================\n",
    "# 1. Import Libraries\n",
    "# =========================\n",
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "from bs4 import BeautifulSoup\n",
    "from shapely import wkt\n",
    "from shapely.geometry import Point, Polygon\n",
    "from sqlalchemy import create_engine\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f23229a6-4bff-45ed-9fba-9bb210db9a9a",
   "metadata": {},
   "source": [
    "### Extract, Transform and Load - Household, Planning Area, And Supermarket data to cloud-based PostgreSQL  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7382d96f-5a79-451d-a4c4-fe3c59ecdd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ----------------------------\n",
    "# Database Connection\n",
    "# ----------------------------\n",
    "engine = create_engine('postgresql://', echo=False)\n",
    "\n",
    "# ----------------------------\n",
    "# 1. Household Population ETL\n",
    "# ----------------------------\n",
    "def etl_population():\n",
    "    dataset_id = \"d_0ef47f84a0776b27010b242038ea2c6b\"\n",
    "    url = f\"https://data.gov.sg/api/action/datastore_search?resource_id={dataset_id}\"\n",
    "    response = requests.get(url)\n",
    "    records = response.json()['result']['records']\n",
    "\n",
    "    # Transform\n",
    "    df = pd.json_normalize(records)\n",
    "    df.rename(columns={\"Number\": \"area\"}, inplace=True)\n",
    "    df.drop(['_id'], axis=1, inplace=True)\n",
    "    df.set_index('area', inplace=True)\n",
    "\n",
    "    # Load\n",
    "    df.to_sql('population', con=engine, if_exists='fail')\n",
    "    print(\"Household Population ETL complete\")\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# 2.Planning Area ETL\n",
    "# ----------------------------\n",
    "def etl_planning_area():\n",
    "    dataset_id = \"d_4765db0e87b9c86336792efe8a1f7a66\"\n",
    "    url = f\"https://api-open.data.gov.sg/v1/public/api/datasets/{dataset_id}/poll-download\"\n",
    "    response = requests.get(url)\n",
    "    data_url = response.json()['data']['url']\n",
    "    geojson_data = requests.get(data_url).json()\n",
    "\n",
    "    # Transform\n",
    "    gdf = gpd.GeoDataFrame.from_features(geojson_data['features'])\n",
    "    \n",
    "    # Extract area names from HTML Description\n",
    "    for i in range(len(gdf)):\n",
    "        soup = BeautifulSoup(gdf['Description'][i], 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        first_row = table.find_all('tr')[1]\n",
    "        area = first_row.find_all('td')[0].text.strip()\n",
    "        gdf.loc[i, 'Description'] = area\n",
    "\n",
    "    gdf = gdf.set_axis(['geometry','name','area'], axis=1)\n",
    "    gdf['area'] = gdf['area'].str.title()\n",
    "    gdf.set_index('area', inplace=True)\n",
    "    gdf.drop(['name'], axis=1, inplace=True)\n",
    "\n",
    "    # Load\n",
    "    gdf.drop(columns=['geometry'], inplace=True)\n",
    "    gdf.to_sql('planning_area', con=engine, if_exists='fail')\n",
    "    print(\"Planning Area ETL complete\")\n",
    "    return gdf\n",
    "\n",
    "# ----------------------------\n",
    "# 3. Supermarkets ETL\n",
    "# ----------------------------\n",
    "def etl_supermarkets(planning_area_path='planning_area.csv'):\n",
    "    dataset_id = \"d_cac2c32f01960a3ad7202a99c27268a0\"\n",
    "    url = f\"https://api-open.data.gov.sg/v1/public/api/datasets/{dataset_id}/poll-download\"\n",
    "    response = requests.get(url)\n",
    "    data_url = response.json()['data']['url']\n",
    "    geojson_data = requests.get(data_url).json()\n",
    "\n",
    "    # Transform\n",
    "    gdf = gpd.GeoDataFrame.from_features(geojson_data['features'])\n",
    "\n",
    "    # Extract key values from Description table\n",
    "    for i in range(len(gdf)):\n",
    "        soup = BeautifulSoup(gdf['Description'][i], 'html.parser')\n",
    "        table = soup.find('table')\n",
    "        rows = table.find_all('tr')\n",
    "        for row in rows[1:]:\n",
    "            cols = row.find_all(['th','td'])\n",
    "            if len(cols)==2:\n",
    "                key = cols[0].text.strip()\n",
    "                value = cols[1].text.strip()\n",
    "                gdf.loc[i,key] = value\n",
    "\n",
    "    gdf.drop(['Name','Description','LIC_NO','INC_CRC','FMEL_UPD_D'], axis=1, inplace=True)\n",
    "    gdf.columns = gdf.columns.str.lower()\n",
    "\n",
    "    # Spatial join: map each supermarket to planning area\n",
    "    gdf['geometry'] = gdf['geometry'].apply(wkt.loads)\n",
    "    planning_area = gpd.read_file(planning_area_path)\n",
    "    planning_area['geometry'] = planning_area['geometry'].apply(wkt.loads)\n",
    "    planning_area.set_index('area', inplace=True)\n",
    "\n",
    "    for idx, row in gdf.iterrows():\n",
    "        coord = row['geometry']\n",
    "        for area_idx, area_row in planning_area.iterrows():\n",
    "            if area_row['geometry'].contains(coord):\n",
    "                gdf.loc[idx,'planning_area'] = area_idx\n",
    "                break\n",
    "\n",
    "    gdf.drop('geometry', axis=1, inplace=True)\n",
    "\n",
    "    # Load\n",
    "    gdf.to_sql('supermarkets', con=engine, if_exists='fail')\n",
    "    print(\"Supermarkets ETL complete\")\n",
    "    return gdf\n",
    "\n",
    "# ----------------------------\n",
    "# Run all ETLs\n",
    "# ----------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    df_population = etl_population()\n",
    "    df_planning = etl_planning_area()\n",
    "    df_supermarkets = etl_supermarkets()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
